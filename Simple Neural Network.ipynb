{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electricity Demand Prediction Using Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gandh\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = np.loadtxt('X_train1.txt', dtype=float)\n",
    "X_train2 = np.loadtxt('X_train2.txt', dtype=float)\n",
    "X_val1 = np.loadtxt('X_val1.txt', dtype=float)\n",
    "X_val2 = np.loadtxt('X_val2.txt', dtype=float)\n",
    "X_test1 = np.loadtxt('X_test1.txt', dtype=float)\n",
    "X_test2 = np.loadtxt('X_test2.txt', dtype=float)\n",
    "y_train = np.loadtxt(\"y_train.txt\", dtype=float)\n",
    "y_val = np.loadtxt(\"y_val.txt\", dtype=float)\n",
    "y_test = np.loadtxt(\"y_test.txt\", dtype=float)\n",
    "\n",
    "# Converting W to kW\n",
    "\n",
    "y_train/=1000\n",
    "y_test/=1000\n",
    "y_val/=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((168, 5103), (1, 5103))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.T.shape, y_train[np.newaxis].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Neural Network Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 5103), (200, 1458), (1, 5103), (1, 1458))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2), axis=1)\n",
    "X_val = np.concatenate((X_val1, X_val2), axis=1)\n",
    "\n",
    "X_train = X_train.T\n",
    "X_val = X_val.T\n",
    "\n",
    "y_train=y_train[np.newaxis]\n",
    "y_val=y_val[np.newaxis]\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(shape=[n_x, None], dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=[n_y, None], dtype=tf.float32)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_y, layers=4, layers_dim=[512, 512, 512, 1]):\n",
    "    \n",
    "    tf.set_random_seed(1)\n",
    "    parameters={}\n",
    "    for l in range(layers):\n",
    "        if l == 0:\n",
    "            parameters[\"W\"+str(l+1)] = tf.get_variable(\"W\"+str(l+1), [layers_dim[l], n_x], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "            parameters[\"b\"+str(l+1)] = tf.get_variable(\"b\"+str(l+1), [layers_dim[l], 1], initializer=tf.zeros_initializer())\n",
    "        else:\n",
    "            parameters[\"W\"+str(l+1)] = tf.get_variable(\"W\"+str(l+1), [layers_dim[l], layers_dim[l-1]], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "            parameters[\"b\"+str(l+1)] = tf.get_variable(\"b\"+str(l+1), [layers_dim[l], 1], initializer=tf.zeros_initializer())\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(512, 12288) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(512, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(512, 512) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(512, 1) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(512, 512) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(512, 1) dtype=float32_ref>\n",
      "W4 = <tf.Variable 'W4:0' shape=(1, 512) dtype=float32_ref>\n",
      "b4 = <tf.Variable 'b4:0' shape=(1, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters(12288, 6)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "    print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "    print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "    print(\"b4 = \" + str(parameters[\"b4\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, activation_types=[\"relu\",\"relu\",\"relu\",\"relu\"]):\n",
    "    mul = {}\n",
    "    L = int(len(parameters)/2)\n",
    "    for l in range(L):\n",
    "        if l == 0:\n",
    "            mul[\"Z\"+str(l+1)] = parameters[\"W\"+str(l+1)] @ X + parameters[\"b\"+str(l+1)]\n",
    "        else:\n",
    "            mul[\"Z\"+str(l+1)] = parameters[\"W\"+str(l+1)] @ mul[\"A\"+str(l)] + parameters[\"b\"+str(l+1)]\n",
    "        if activation_types[l] == \"relu\":\n",
    "            mul[\"A\"+str(l+1)] = tf.nn.relu(mul[\"Z\"+str(l+1)])\n",
    "        elif activation_types[l] == \"sigmoid\":\n",
    "            mul[\"A\"+str(l+1)] = tf.nn.sigmoid(mul[\"Z\"+str(l+1)])\n",
    "        else:\n",
    "            mul[\"A\"+str(l+1)] = mul[\"Z\"+str(l+1)]\n",
    "        \n",
    "    return mul[\"A\"+str(int(len(parameters)/2))]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y, cost_type=\"mse\"):\n",
    "#     m = Y.shape[0]\n",
    "    cost = tf.reduce_mean((AL-Y)**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_minibatches(X, Y, mini_batch_size=64, seed=1):\n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:, k*mini_batch_size: (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k*mini_batch_size: (k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches:]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 15.129735\n",
      "Cost after epoch 50: 0.320626\n"
     ]
    }
   ],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.001, num_epochs=200, print_cost=True, mini_batch_size=64):\n",
    "    ops.reset_default_graph()\n",
    "#     tf.set_random_seed(1)\n",
    "    (n_x, m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs=[]\n",
    "    \n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    \n",
    "    parameters = initialize_parameters(n_x, n_y)\n",
    "    \n",
    "    AL = forward_propagation(X, parameters)\n",
    "    \n",
    "    cost = compute_cost(AL, Y)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0.\n",
    "            num_minibatches = m/mini_batch_size\n",
    "            minibatches = random_minibatches(X_train, Y_train)\n",
    "            for minibatch in minibatches:\n",
    "                minibatch_X, minibatch_Y = minibatch\n",
    "                _, minibatch_cost = sess.run((optimizer, cost), feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                epoch_cost += minibatch_cost/num_minibatches\n",
    "                \n",
    "            if print_cost == True:\n",
    "                if epoch%50==0:\n",
    "                    costs.append(epoch_cost)\n",
    "                    if epoch%50==0:\n",
    "                        print(\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                        \n",
    "        parameters = sess.run(parameters)\n",
    "        accuracy = tf.reduce_mean(1-AL/Y)\n",
    "\n",
    "        print(\"Train accuracy: \", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Test accuracy: \", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "parameters = model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X_test1, X_test2), axis=1)\n",
    "X_test = X_test.T\n",
    "y_test=y_test.reshape(1, -1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(200, 1)\n",
    "    AL = forward_propagation(X, parameters)\n",
    "#     print(tf.Variable(AL, validate_shape=False).eval())\n",
    "#     pred = tf.reduce_uniform(AL)\n",
    "#     print(pred)\n",
    "    pred = (AL.eval({X: X_test}))\n",
    "    accuracy = tf.reduce_mean(tf.abs(1-AL/Y))\n",
    "    mse_test = tf.reduce_mean((AL-Y)**2).eval({X: X_test, Y: y_test})\n",
    "    mse_train = tf.reduce_mean((AL-Y)**2).eval({X: X_train, Y: y_train})\n",
    "    mse_val = tf.reduce_mean((AL-Y)**2).eval({X: X_val, Y: y_val})\n",
    "    print(\"Train accuracy: \", (1-accuracy.eval({X: X_train, Y: y_train}))*100,\"%\")\n",
    "    print(\"Validation accuracy: \", (1-accuracy.eval({X: X_val, Y: y_val}))*100,\"%\")\n",
    "    print(\"Test accuracy: \", (1-accuracy.eval({X: X_test, Y: y_test}))*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train MSE:', mse_train)\n",
    "print('Val MSE:', mse_val)\n",
    "print('Test MSE:', mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting $R^2$ Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x,y,x_label=None,y_label=None, title=None, style1=None, color1=None, label1=None, y2=None, label2=None, \\\n",
    "           style2=None, color2=None):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plot1 = plt.scatter(x, y, color=color1)\n",
    "    plot2, = plt.plot([(y_test).min(), (y_test).max()], [(y_test).min(), (y_test).max()], 'k--', lw=4)\n",
    "    plt.legend([plot1], [label1, label2])\n",
    "    plt.show()\n",
    "    \n",
    "plot(y_test, pred, 'Actual Load (kWh)', 'Predicted Load (kWh)',  'Simple Neural Network', \\\n",
    "       style1='.', color1='blue', label1='Predicted', y2=y_test, label2='Actual', \\\n",
    "       style2='--', color2='black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
